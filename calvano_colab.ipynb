{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calvano et al. (2020) Q-Learning Replication (Colab)\n",
    "\n",
    "このノートブックは Calvano et al. (2020) の Q学習による価格付け実験を Google Colab 上で再現します。\n",
    "\n",
    "**論文**: Calvano, E., Calzolari, G., Denicolò, V., & Pastorello, S. (2020). Artificial Intelligence, Algorithmic Pricing, and Collusion. *American Economic Review*, 110(10), 3267-3297.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 実行手順\n",
    "\n",
    "1. **セットアップ**: セクション1-2を順番に実行\n",
    "2. **ベンチマーク計算**: セクション3で理論値を確認\n",
    "3. **実験選択**: セクション4で実験レベルを選択\n",
    "   - **クイックテスト**: 100エピソード（約5分）\n",
    "   - **フル実験**: 50,000エピソード（8-12時間）\n",
    "4. **結果確認**: セクション5で学習結果を可視化\n",
    "5. **並列実験**: セクション6でTable A.2を再現（オプション）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 1. セットアップ（リポジトリのクローン＆依存パッケージのインストール）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リポジトリをクローン（並列実行対応ブランチ）\n",
    "!git clone -b parallel-colab https://github.com/Yusei406/calvano-thesis.git\n",
    "%cd calvano-thesis\n",
    "\n",
    "# 現在のディレクトリを確認\n",
    "!pwd\n",
    "!ls -la\n",
    "\n",
    "# 依存パッケージをインストール\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# パッケージが正しくインストールされたか確認\n",
    "import sys\n",
    "import os\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "# 現在の作業ディレクトリを取得\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "# myprojectディレクトリの存在確認\n",
    "if os.path.exists('myproject'):\n",
    "    print(\"✅ myprojectディレクトリが見つかりました\")\n",
    "    print(\"📁 myproject内容:\")\n",
    "    !ls -la myproject/\n",
    "else:\n",
    "    print(\"❌ myprojectディレクトリが見つかりません\")\n",
    "    print(\"📁 現在のディレクトリ内容:\")\n",
    "    !ls -la\n",
    "\n",
    "print(\"✅ セットアップ完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 2. モジュールのインポート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 現在のディレクトリをPythonパスに追加\n",
    "sys.path.append('.')\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "print(f\"📍 現在のディレクトリ: {os.getcwd()}\")\n",
    "print(f\"📁 myprojectの存在確認: {os.path.exists('myproject')}\")\n",
    "\n",
    "# 必要なモジュールをインポート\n",
    "try:\n",
    "    from myproject.env import DemandEnvironment\n",
    "    from myproject.agent import QLearningAgent\n",
    "    from myproject.train import train_agents\n",
    "    print(\"✅ myprojectモジュールのインポート成功\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ myprojectモジュールのインポートエラー: {e}\")\n",
    "    print(\"📋 利用可能なファイル:\")\n",
    "    !find . -name \"*.py\" | head -10\n",
    "    raise\n",
    "\n",
    "# 標準ライブラリとサードパーティライブラリ\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✅ 全モジュールのインポート完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 3. 環境セットアップとベンチマーク計算（Nash/協調均衡）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calvanoパラメータで環境を作成\n",
    "env = DemandEnvironment(\n",
    "    demand_intercept=0.0,   # a_0 (outside option)\n",
    "    product_quality=2.0,    # a_i (product quality)\n",
    "    demand_slope=0.25,      # μ (price sensitivity)\n",
    "    marginal_cost=1.0       # c (marginal cost)\n",
    ")\n",
    "\n",
    "# Nash均衡・協調均衡を計算\n",
    "nash_eq = env.get_nash_equilibrium()\n",
    "coop_eq = env.get_collusive_outcome()\n",
    "\n",
    "print('📊 ベンチマーク均衡の計算結果:')\n",
    "print()\n",
    "print('Nash Equilibrium:')\n",
    "print(f'  Price: {nash_eq[\"prices\"][0]:.3f}')\n",
    "print(f'  Individual Profit: {nash_eq[\"individual_profit\"]:.3f}')\n",
    "print(f'  Joint Profit: {nash_eq[\"joint_profit\"]:.3f}')\n",
    "print()\n",
    "print('Cooperative Equilibrium:')\n",
    "print(f'  Price: {coop_eq[\"prices\"][0]:.3f}')\n",
    "print(f'  Individual Profit: {coop_eq[\"individual_profit\"]:.3f}')\n",
    "print(f'  Joint Profit: {coop_eq[\"joint_profit\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 4. Q学習エージェントの学習実験\n",
    "\n",
    "⚠️ **重要**: 下記のコメントアウトを調整して実験レベルを選択してください\n",
    "\n",
    "- **クイックテスト**: 100エピソード（約5分）- デフォルトで有効\n",
    "- **フル実験**: 50,000エピソード（8-12時間）- コメントアウトを外して使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. クイックテスト（約5分）\n",
    "print('🚀 クイックテスト実験を開始...')\n",
    "agents, env, history = train_agents(\n",
    "    n_episodes=100,\n",
    "    iterations_per_episode=1000,\n",
    "    learning_rate=0.15,\n",
    "    discount_factor=0.95,\n",
    "    epsilon_decay_beta=4e-6,\n",
    "    memory_length=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 2. フル実験（8-12時間）- コメントアウトを外して使用\n",
    "# print('🚀 フル実験（論文レベル）を開始...')\n",
    "# print('⚠️  予想実行時間: 8-12時間')\n",
    "# agents, env, history = train_agents(\n",
    "#     n_episodes=50000,\n",
    "#     iterations_per_episode=25000,\n",
    "#     learning_rate=0.15,\n",
    "#     discount_factor=0.95,\n",
    "#     epsilon_decay_beta=4e-6,\n",
    "#     memory_length=1,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "print('\\n✅ 学習完了!')\n",
    "print(f'Final individual profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f}')\n",
    "print(f'Final joint profit: {history[\"training_summary\"][\"final_joint_profit\"]:.4f}')\n",
    "print(f'Nash ratio (individual): {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 5. 学習履歴の可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果のプロット\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 個別利益の推移\n",
    "axes[0, 0].plot(history['episodes'], history['individual_profits'], 'b-', linewidth=2)\n",
    "axes[0, 0].axhline(y=nash_eq['individual_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[0, 0].axhline(y=coop_eq['individual_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[0, 0].set_title('Individual Profits', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Profit')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 合計利益の推移\n",
    "axes[0, 1].plot(history['episodes'], history['joint_profits'], 'b-', linewidth=2)\n",
    "axes[0, 1].axhline(y=nash_eq['joint_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[0, 1].axhline(y=coop_eq['joint_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[0, 1].set_title('Joint Profits', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Profit')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Nash比\n",
    "nash_ratios = [p / nash_eq['individual_profit'] for p in history['individual_profits']]\n",
    "axes[1, 0].plot(history['episodes'], nash_ratios, 'orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=1.0, color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[1, 0].set_title('Individual Profit / Nash Profit', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Ratio')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Epsilon減衰\n",
    "axes[1, 1].plot(history['episodes'], history['epsilon_values'], 'purple', linewidth=2)\n",
    "axes[1, 1].set_title('Epsilon Decay', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Episode')\n",
    "axes[1, 1].set_ylabel('Epsilon')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('📈 最終結果:')\n",
    "print(f'Individual Profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f}')\n",
    "print(f'Joint Profit: {history[\"training_summary\"][\"final_joint_profit\"]:.4f}')\n",
    "print(f'Nash Ratio: {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f}')\n",
    "\n",
    "# 協調均衡との比較を手動計算\n",
    "coop_ratio_individual = history[\"training_summary\"][\"final_individual_profit\"] / coop_eq['individual_profit']\n",
    "coop_ratio_joint = history[\"training_summary\"][\"final_joint_profit\"] / coop_eq['joint_profit']\n",
    "print(f'Cooperative Ratio (Individual): {coop_ratio_individual:.3f}')\n",
    "print(f'Cooperative Ratio (Joint): {coop_ratio_joint:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 6. 並列実験でTable A.2を再現（オプション）\n",
    "\n",
    "**論文の完全再現**を行う場合は、以下のフル実験を実行してください：\n",
    "\n",
    "- **クイックテスト**: 1,000エピソード × 2シード（約10分）\n",
    "- **フル実験**: 50,000エピソード × 10シード（8-12時間）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 並列実験スクリプトの存在確認\n",
    "import os\n",
    "script_path = 'myproject/scripts/table_a2_parallel.py'\n",
    "if os.path.exists(script_path):\n",
    "    print(f\"✅ 並列実験スクリプトが見つかりました: {script_path}\")\n",
    "    \n",
    "    # 1. クイックテスト並列実験（約10分）\n",
    "    print(\"🚀 クイックテスト並列実験を開始...\")\n",
    "    !python -m myproject.scripts.table_a2_parallel --episodes 1000 --n-seeds 2 --n-sessions 2 --max-workers 2\n",
    "    \n",
    "    # 2. フル実験（8-12時間）- 論文の完全再現（コメントアウトを外して使用）\n",
    "    # print(\"🚀 フル並列実験（Table A.2完全再現）を開始...\")\n",
    "    # print(\"📊 パラメータ: 50,000エピソード × 10シード\")\n",
    "    # print(\"⏰ 予想実行時間: 8-12時間\")\n",
    "    # !python -m myproject.scripts.table_a2_parallel --episodes 50000 --n-seeds 10 --n-sessions 4 --max-workers 4\n",
    "    \n",
    "    print(\"✅ 並列実験完了!\")\n",
    "else:\n",
    "    print(f\"❌ 並列実験スクリプトが見つかりません: {script_path}\")\n",
    "    print(\"📋 利用可能なスクリプト:\")\n",
    "    !find myproject -name \"*.py\" -type f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 7. 結果の確認とダウンロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果ファイルの確認\n",
    "import os\n",
    "try:\n",
    "    from google.colab import files\n",
    "    colab_available = True\n",
    "    print(\"✅ Google Colab環境を検出\")\n",
    "except ImportError:\n",
    "    colab_available = False\n",
    "    print(\"ℹ️  ローカル環境で実行中\")\n",
    "\n",
    "print(\"\\n📁 生成されたファイル:\")\n",
    "if os.path.exists('results'):\n",
    "    for root, dirs, files_list in os.walk('results'):\n",
    "        for file in files_list:\n",
    "            if file.endswith('.csv'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                print(f\"  {filepath}\")\n",
    "                \n",
    "    # CSVファイルの内容を表示\n",
    "    if os.path.exists('results/table_a2_parallel.csv'):\n",
    "        print(\"\\n📊 Table A.2 結果:\")\n",
    "        df = pd.read_csv('results/table_a2_parallel.csv')\n",
    "        print(df)\n",
    "        \n",
    "        # 期待値との比較\n",
    "        print(\"\\n🎯 論文の期待値:\")\n",
    "        print(\"Individual profit: 0.18 ± 0.03\")\n",
    "        print(\"Joint profit: 0.26 ± 0.04\")\n",
    "        \n",
    "        # ファイルダウンロード（Colab環境の場合のみ）\n",
    "        if colab_available:\n",
    "            print(\"\\n⬇️  結果ファイルをダウンロード:\")\n",
    "            files.download('results/table_a2_parallel.csv')\n",
    "        else:\n",
    "            print(f\"\\n📄 結果ファイルの場所: {os.path.abspath('results/table_a2_parallel.csv')}\")\n",
    "    else:\n",
    "        print(\"⚠️  results/table_a2_parallel.csv が見つかりません。\")\n",
    "        print(\"📋 resultsディレクトリの内容:\")\n",
    "        !ls -la results/\n",
    "else:\n",
    "    print(\"❌ resultsディレクトリが見つかりません。\")\n",
    "    print(\"📋 現在のディレクトリの内容:\")\n",
    "    !ls -la\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## 📚 参考情報\n",
    "\n",
    "### 期待される結果（論文Table A.2）\n",
    "- **Individual profit**: 0.18 ± 0.03\n",
    "- **Joint profit**: 0.26 ± 0.04\n",
    "- **Nash ratio**: > 100% (協調的行動を示唆)\n",
    "\n",
    "### パラメータ設定\n",
    "- **環境**: a₀=0.0, aᵢ=2.0, μ=0.25, c=1.0\n",
    "- **Q学習**: α=0.15, γ=0.95, β=4×10⁻⁶, memory=1\n",
    "\n",
    "### 実行時間の目安\n",
    "- **クイックテスト**: 100エピソード（約5分）\n",
    "- **中規模実験**: 1,000エピソード（約30分）\n",
    "- **フル実験**: 50,000エピソード（8-12時間）\n",
    "\n",
    "**🎓 論文**: Calvano, E., Calzolari, G., Denicolò, V., & Pastorello, S. (2020). *Artificial Intelligence, Algorithmic Pricing, and Collusion*. American Economic Review, 110(10), 3267-3297.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 🔧 トラブルシューティング\n",
    "\n",
    "### よくあるエラーと解決方法\n",
    "\n",
    "**1. `ModuleNotFoundError: No module named 'myproject'`**\n",
    "- セクション1のセットアップセルを正しく実行したか確認\n",
    "- `%cd calvano-thesis` が正しく動作しているか確認\n",
    "- 以下のコードで診断：\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(f\"現在のディレクトリ: {os.getcwd()}\")\n",
    "print(f\"myprojectが存在: {os.path.exists('myproject')}\")\n",
    "if not os.path.exists('myproject'):\n",
    "    print(\"リポジトリクローンに失敗している可能性があります。セクション1を再実行してください。\")\n",
    "```\n",
    "\n",
    "**2. `requirements.txt` インストールエラー**\n",
    "- Colab環境で必要なパッケージが既にインストール済みの場合があります\n",
    "- エラーが出た場合は個別にインストール: `!pip install numpy scipy matplotlib pandas tqdm`\n",
    "\n",
    "**3. 並列実験エラー**\n",
    "- 並列実験はオプションです。基本実験（セクション4-5）は単体で動作します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calvano et al. (2020) Q-Learning Replication (Colab)\n",
    "\n",
    "このノートブックは Calvano et al. (2020) の Q学習による価格付け実験を Google Colab 上で再現します。\n",
    "\n",
    "**論文**: Calvano, E., Calzolari, G., Denicolò, V., & Pastorello, S. (2020). Artificial Intelligence, Algorithmic Pricing, and Collusion. *American Economic Review*, 110(10), 3267-3297.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 1. セットアップ（リポジトリのクローン＆依存パッケージのインストール）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リポジトリをクローン\n",
    "!git clone https://github.com/Yusei406/calvano-thesis.git\n",
    "%cd calvano-thesis\n",
    "\n",
    "# 依存パッケージをインストール\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 2. モジュールのインポート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from myproject.env import DemandEnvironment\n",
    "from myproject.agent import QLearningAgent\n",
    "from myproject.train import train_agents\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✅ モジュールのインポート完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 3. 環境セットアップとベンチマーク計算（Nash/協調均衡）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calvanoパラメータで環境を作成\n",
    "env = DemandEnvironment(\n",
    "    demand_intercept=0.0,   # a_0 (outside option)\n",
    "    product_quality=2.0,    # a_i (product quality)\n",
    "    demand_slope=0.25,      # μ (price sensitivity)\n",
    "    marginal_cost=1.0       # c (marginal cost)\n",
    ")\n",
    "\n",
    "# Nash均衡・協調均衡を計算\n",
    "nash_eq = env.get_nash_equilibrium()\n",
    "coop_eq = env.get_collusive_outcome()\n",
    "\n",
    "print('📊 ベンチマーク均衡の計算結果:')\n",
    "print('Nash Equilibrium:')\n",
    "print(f'  Price: {nash_eq[\"prices\"][0]:.3f}')\n",
    "print(f'  Individual Profit: {nash_eq[\"individual_profit\"]:.3f}')\n",
    "print(f'  Joint Profit: {nash_eq[\"joint_profit\"]:.3f}')\n",
    "print()\n",
    "print('Cooperative Equilibrium:')\n",
    "print(f'  Price: {coop_eq[\"prices\"][0]:.3f}')\n",
    "print(f'  Individual Profit: {coop_eq[\"individual_profit\"]:.3f}')\n",
    "print(f'  Joint Profit: {coop_eq[\"joint_profit\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 4. Q学習エージェントの学習実験\n",
    "\n",
    "⚠️ **重要**: フル実験は8-12時間かかります。まずはクイックテストを実行してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. クイックテスト（約5分）\n",
    "print('🚀 クイックテスト実験を開始...')\n",
    "agents, env, history = train_agents(\n",
    "    n_episodes=100,\n",
    "    iterations_per_episode=1000,\n",
    "    learning_rate=0.15,\n",
    "    discount_factor=0.95,\n",
    "    epsilon_decay_beta=4e-6,\n",
    "    memory_length=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 2. フル実験（8-12時間）- コメントアウトを外して使用\n",
    "# print('🚀 フル実験（論文レベル）を開始...')\n",
    "# print('⚠️  予想実行時間: 8-12時間')\n",
    "# agents, env, history = train_agents(\n",
    "#     n_episodes=50000,\n",
    "#     iterations_per_episode=25000,\n",
    "#     learning_rate=0.15,\n",
    "#     discount_factor=0.95,\n",
    "#     epsilon_decay_beta=4e-6,\n",
    "#     memory_length=1,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "print('\\\\n✅ 学習完了!')\n",
    "print(f'Final individual profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f}')\n",
    "print(f'Nash ratio: {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 5. 学習履歴の可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果のプロット\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 個別利益の推移\n",
    "axes[0, 0].plot(history['episodes'], history['individual_profits'], 'b-', linewidth=2)\n",
    "axes[0, 0].axhline(y=nash_eq['individual_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[0, 0].axhline(y=coop_eq['individual_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[0, 0].set_title('Individual Profits', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Profit')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 合計利益の推移\n",
    "axes[0, 1].plot(history['episodes'], history['joint_profits'], 'b-', linewidth=2)\n",
    "axes[0, 1].axhline(y=nash_eq['joint_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[0, 1].axhline(y=coop_eq['joint_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[0, 1].set_title('Joint Profits', fontsize=14)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Nash比\n",
    "nash_ratios = [p / nash_eq['individual_profit'] for p in history['individual_profits']]\n",
    "axes[1, 0].plot(history['episodes'], nash_ratios, 'orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=1.0, color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[1, 0].set_title('Individual Profit / Nash Profit', fontsize=14)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Epsilon減衰\n",
    "axes[1, 1].plot(history['episodes'], history['epsilon_values'], 'purple', linewidth=2)\n",
    "axes[1, 1].set_title('Epsilon Decay', fontsize=14)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('📈 最終結果:')\n",
    "print(f'Individual Profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f}')\n",
    "print(f'Nash Ratio: {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 6. 並列実験でTable A.2を再現\n",
    "\n",
    "**論文の完全再現**を行う場合は、以下のフル実験を実行してください：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. クイックテスト並列実験（約10分）\n",
    "print(\"🚀 クイックテスト並列実験を開始...\")\n",
    "!python -m myproject.scripts.table_a2_parallel --episodes 1000 --n-seeds 2 --n-sessions 2 --max-workers 2\n",
    "\n",
    "# 2. フル実験（8-12時間）- 論文の完全再現（コメントアウトを外して使用）\n",
    "# print(\"🚀 フル並列実験（Table A.2完全再現）を開始...\")\n",
    "# print(\"📊 パラメータ: 50,000エピソード × 10シード\")\n",
    "# print(\"⏰ 予想実行時間: 8-12時間\")\n",
    "# !python -m myproject.scripts.table_a2_parallel --episodes 50000 --n-seeds 10 --n-sessions 4 --max-workers 4\n",
    "\n",
    "print(\"✅ 並列実験完了!\")\n",
    "\n",
    "# 結果の確認とダウンロード\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "if os.path.exists('results'):\n",
    "    for file in os.listdir('results'):\n",
    "        if file.endswith('.json'):\n",
    "            print(f\"📊 結果ファイル: {file}\")\n",
    "            files.download(f'results/{file}')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calvano et al. (2020) Q-Learning Replication (Colab)\n",
    "\n",
    "このノートブックは Calvano et al. (2020) の Q学習による価格付け実験を Google Colab 上で再現します。\n",
    "\n",
    "**論文**: Calvano, E., Calzolari, G., Denicolò, V., & Pastorello, S. (2020). Artificial Intelligence, Algorithmic Pricing, and Collusion. *American Economic Review*, 110(10), 3267-3297.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 1. セットアップ（リポジトリのクローン＆依存パッケージのインストール）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リポジトリをクローン\n",
    "!git clone https://github.com/Yusei406/calvano-thesis.git\n",
    "%cd calvano-thesis\n",
    "\n",
    "# 依存パッケージをインストール\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. モジュールのインポート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from myproject.env import DemandEnvironment\n",
    "from myproject.agent import QLearningAgent\n",
    "from myproject.train import train_agents\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✅ モジュールのインポート完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. 環境セットアップとベンチマーク計算（Nash/協調均衡）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calvanoパラメータで環境を作成\n",
    "env = DemandEnvironment(\n",
    "    demand_intercept=0.0,   # a_0 (outside option)\n",
    "    product_quality=2.0,    # a_i (product quality)\n",
    "    demand_slope=0.25,      # μ (price sensitivity)\n",
    "    marginal_cost=1.0       # c (marginal cost)\n",
    ")\n",
    "\n",
    "# Nash均衡・協調均衡を計算\n",
    "nash_eq = env.get_nash_equilibrium()\n",
    "coop_eq = env.get_collusive_outcome()\n",
    "\n",
    "print('📊 ベンチマーク均衡の計算結果:')\n",
    "print()\n",
    "print('Nash Equilibrium:')\n",
    "print(f'  Price: {nash_eq[\"prices\"][0]:.3f}')\n",
    "print(f'  Individual Profit: {nash_eq[\"individual_profit\"]:.3f}')\n",
    "print(f'  Joint Profit: {nash_eq[\"joint_profit\"]:.3f}')\n",
    "print()\n",
    "print('Cooperative Equilibrium:')\n",
    "print(f'  Price: {coop_eq[\"prices\"][0]:.3f}')\n",
    "print(f'  Individual Profit: {coop_eq[\"individual_profit\"]:.3f}')\n",
    "print(f'  Joint Profit: {coop_eq[\"joint_profit\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Q学習エージェントの学習実験\n",
    "\n",
    "⚠️ **重要**: 下記のコメントアウトを調整して実行レベルを選択してください\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. クイックテスト（約5分）\n",
    "print('🚀 クイックテスト実験を開始...')\n",
    "agents, env, history = train_agents(\n",
    "    n_episodes=100,\n",
    "    iterations_per_episode=1000,\n",
    "    learning_rate=0.15,\n",
    "    discount_factor=0.95,\n",
    "    epsilon_decay_beta=4e-6,\n",
    "    memory_length=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 2. 中規模実験（約30分）- コメントアウトを外して使用\n",
    "# print('🚀 中規模実験を開始...')\n",
    "# agents, env, history = train_agents(\n",
    "#     n_episodes=1000,\n",
    "#     iterations_per_episode=5000,\n",
    "#     learning_rate=0.15,\n",
    "#     discount_factor=0.95,\n",
    "#     epsilon_decay_beta=4e-6,\n",
    "#     memory_length=1,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# 3. フル実験（8-12時間）- 論文の完全再現（コメントアウトを外して使用）\n",
    "# print('🚀 フル実験（論文レベル）を開始...')\n",
    "# print('⚠️  予想実行時間: 8-12時間')\n",
    "# agents, env, history = train_agents(\n",
    "#     n_episodes=50000,\n",
    "#     iterations_per_episode=25000,\n",
    "#     learning_rate=0.15,\n",
    "#     discount_factor=0.95,\n",
    "#     epsilon_decay_beta=4e-6,\n",
    "#     memory_length=1,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "print('\\n✅ 学習完了!')\n",
    "print(f'Final individual profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f}')\n",
    "print(f'Final joint profit: {history[\"training_summary\"][\"final_joint_profit\"]:.4f}')\n",
    "print(f'Nash ratio (individual): {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. 学習履歴の可視化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果のプロット\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 個別利益の推移\n",
    "axes[0, 0].plot(history['episodes'], history['individual_profits'], 'b-', linewidth=2)\n",
    "axes[0, 0].axhline(y=nash_eq['individual_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[0, 0].axhline(y=coop_eq['individual_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[0, 0].set_title('Individual Profits', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Episode')\n",
    "axes[0, 0].set_ylabel('Profit')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 合計利益の推移\n",
    "axes[0, 1].plot(history['episodes'], history['joint_profits'], 'b-', linewidth=2)\n",
    "axes[0, 1].axhline(y=nash_eq['joint_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[0, 1].axhline(y=coop_eq['joint_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[0, 1].set_title('Joint Profits', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Episode')\n",
    "axes[0, 1].set_ylabel('Profit')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Epsilon減衰\n",
    "axes[1, 0].plot(history['episodes'], history['epsilon_values'], 'purple', linewidth=2)\n",
    "axes[1, 0].set_title('Epsilon Decay', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Episode')\n",
    "axes[1, 0].set_ylabel('Epsilon')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Nash比\n",
    "nash_ratios = [p / nash_eq['individual_profit'] for p in history['individual_profits']]\n",
    "axes[1, 1].plot(history['episodes'], nash_ratios, 'orange', linewidth=2)\n",
    "axes[1, 1].axhline(y=1.0, color='r', linestyle='--', label='Nash', linewidth=2)\n",
    "axes[1, 1].axhline(y=coop_eq['individual_profit'] / nash_eq['individual_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
    "axes[1, 1].set_title('Individual Profit / Nash Profit', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Episode')\n",
    "axes[1, 1].set_ylabel('Ratio')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 最終結果の表示\n",
    "print('📈 最終結果:')\n",
    "print(f'Individual Profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f} (Nash比: {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f})')\n",
    "print(f'Joint Profit: {history[\"training_summary\"][\"final_joint_profit\"]:.4f}')\n",
    "print(f'Final Epsilon: {history[\"training_summary\"][\"final_epsilon\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. （オプション）並列実験でTable A.2を再現\n",
    "\n",
    "大規模実験を行いたい場合は、以下のコマンドを実行してください：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. クイックテスト並列実験（約10分）\n",
    "print(\"🚀 クイックテスト並列実験を開始...\")\n",
    "!python -m myproject.scripts.table_a2_parallel --episodes 1000 --n-seeds 2 --n-sessions 2 --max-workers 2\n",
    "\n",
    "# 2. 中規模実験（約60分）- コメントアウトを外して実行\n",
    "# print(\"🚀 中規模並列実験を開始...\")\n",
    "# !python -m myproject.scripts.table_a2_parallel --episodes 5000 --n-seeds 5 --n-sessions 2 --max-workers 4\n",
    "\n",
    "# 3. フル実験（8-12時間）- 論文の完全再現（コメントアウトを外して実行）\n",
    "# print(\"🚀 フル並列実験（Table A.2完全再現）を開始...\")\n",
    "# print(\"📊 パラメータ: 50,000エピソード × 10シード\")\n",
    "# print(\"⏰ 予想実行時間: 8-12時間\")\n",
    "# !python -m myproject.scripts.table_a2_parallel --episodes 50000 --n-seeds 10 --n-sessions 4 --max-workers 4 --output-dir results\n",
    "\n",
    "print(\"✅ 並列実験完了!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. 結果のダウンロードと分析\n",
    "\n",
    "並列実験を実行した場合、結果をダウンロードして分析できます：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果ファイルの確認とダウンロード\n",
    "import os\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "# 結果ディレクトリの確認\n",
    "print(\"📁 実験結果ファイル:\")\n",
    "if os.path.exists('results'):\n",
    "    result_files = []\n",
    "    for file in os.listdir('results'):\n",
    "        if file.endswith('.json'):\n",
    "            print(f\"  📊 {file}\")\n",
    "            result_files.append(file)\n",
    "        elif file.endswith('.csv'):\n",
    "            print(f\"  📈 {file}\")\n",
    "    \n",
    "    # 最新の結果を分析\n",
    "    if result_files:\n",
    "        latest_result = max(result_files, key=lambda f: os.path.getctime(f'results/{f}'))\n",
    "        print(f\"\\n🔍 最新結果の分析: {latest_result}\")\n",
    "        \n",
    "        with open(f'results/{latest_result}', 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Table A.2形式の結果表示\n",
    "        if 'sessions' in data:\n",
    "            df = pd.DataFrame(data['sessions'])\n",
    "            if not df.empty:\n",
    "                print(f\"\\n📊 Table A.2 スタイルの結果:\")\n",
    "                print(f\"シード数: {len(df['seed'].unique())}\")\n",
    "                print(f\"セッション数: {len(df)}\")\n",
    "                print(f\"個別利益: {df['final_individual_profit'].mean():.4f} ± {df['final_individual_profit'].std():.4f}\")\n",
    "                print(f\"合計利益: {df['final_joint_profit'].mean():.4f} ± {df['final_joint_profit'].std():.4f}\")\n",
    "                print(f\"Nash比 (個別): {df['nash_ratio_individual'].mean():.3f}\")\n",
    "        \n",
    "        # ダウンロード実行\n",
    "        print(f\"\\n💾 結果ファイルをダウンロード中...\")\n",
    "        files.download(f'results/{latest_result}')\n",
    "        \n",
    "else:\n",
    "    print(\"  ❌ 結果ファイルがありません。まず並列実験を実行してください。\")\n",
    "\n",
    "print(\"\\n✅ ダウンロード完了!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. 📋 論文レベル実験の実行手順\n",
    "\n",
    "**Calvano et al. (2020) Table A.2の完全再現**を行う場合の推奨手順：\n",
    "\n",
    "### ステップ1: 動作確認\n",
    "- まず**クイックテスト**（セクション4 & 6）を実行して動作を確認\n",
    "\n",
    "### ステップ2: 中規模実験\n",
    "- **中規模実験**（セクション6）のコメントアウトを外して実行（約60分）\n",
    "- 結果をダウンロードして確認\n",
    "\n",
    "### ステップ3: フル実験\n",
    "- **フル実験**（セクション6）のコメントアウトを外して実行\n",
    "- ⚠️ **8-12時間**かかるため、時間に余裕があるときに実行\n",
    "- 実行パラメータ：\n",
    "  - **50,000エピソード × 10シード**\n",
    "  - **25,000 iterations per episode**\n",
    "  - **論文と同一のパラメータ**\n",
    "\n",
    "### 期待される結果（論文Table A.2）\n",
    "- **個別利益**: 0.18 ± 0.03\n",
    "- **合計利益**: 0.26 ± 0.04  \n",
    "- **Nash比**: 約1.2-1.4 (協調的行動の証拠)\n",
    "\n",
    "### 💡 ヒント\n",
    "- Colab Pro/Pro+の使用を推奨（タイムアウト防止）\n",
    "- 実験中はタブを閉じないでください\n",
    "- 結果は自動的に`results/`に保存されます\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
