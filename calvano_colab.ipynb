<<<<<<< HEAD
 
=======
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Calvano et al. (2020) Q-Learning Replication (Colab)\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ Calvano et al. (2020) ã® Qå­¦ç¿’ã«ã‚ˆã‚‹ä¾¡æ ¼ä»˜ã‘å®Ÿé¨“ã‚’ Google Colab ä¸Šã§å†ç¾ã—ã¾ã™ã€‚\n",
        "\n",
        "**è«–æ–‡**: Calvano, E., Calzolari, G., DenicolÃ², V., & Pastorello, S. (2020). Artificial Intelligence, Algorithmic Pricing, and Collusion. *American Economic Review*, 110(10), 3267-3297.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ï¼†ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³\n",
        "!git clone https://github.com/Yusei406/calvano-thesis.git\n",
        "%cd calvano-thesis\n",
        "\n",
        "# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "from myproject.env import DemandEnvironment\n",
        "from myproject.agent import QLearningAgent\n",
        "from myproject.train import train_agents\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print(\"âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è¨ˆç®—ï¼ˆNash/å”èª¿å‡è¡¡ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calvanoãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç’°å¢ƒã‚’ä½œæˆ\n",
        "env = DemandEnvironment(\n",
        "    demand_intercept=0.0,   # a_0 (outside option)\n",
        "    product_quality=2.0,    # a_i (product quality)\n",
        "    demand_slope=0.25,      # Î¼ (price sensitivity)\n",
        "    marginal_cost=1.0       # c (marginal cost)\n",
        ")\n",
        "\n",
        "# Nashå‡è¡¡ãƒ»å”èª¿å‡è¡¡ã‚’è¨ˆç®—\n",
        "nash_eq = env.get_nash_equilibrium()\n",
        "coop_eq = env.get_collusive_outcome()\n",
        "\n",
        "print('ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å‡è¡¡ã®è¨ˆç®—çµæœ:')\n",
        "print()\n",
        "print('Nash Equilibrium:')\n",
        "print(f'  Price: {nash_eq[\"prices\"][0]:.3f}')\n",
        "print(f'  Individual Profit: {nash_eq[\"individual_profit\"]:.3f}')\n",
        "print(f'  Joint Profit: {nash_eq[\"joint_profit\"]:.3f}')\n",
        "print()\n",
        "print('Cooperative Equilibrium:')\n",
        "print(f'  Price: {coop_eq[\"prices\"][0]:.3f}')\n",
        "print(f'  Individual Profit: {coop_eq[\"individual_profit\"]:.3f}')\n",
        "print(f'  Joint Profit: {coop_eq[\"joint_profit\"]:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Qå­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å­¦ç¿’å®Ÿé¨“\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’å®Ÿé¨“è¨­å®šã®é¸æŠ\n",
        "# âš ï¸ æ³¨æ„: ãƒ•ãƒ«å®Ÿé¨“ã¯8-12æ™‚é–“ã‹ã‹ã‚Šã¾ã™ï¼ã¾ãšã¯ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’æ¨å¥¨\n",
        "\n",
        "# === ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ï¼ˆç´„5åˆ†ï¼‰ ===\n",
        "n_episodes_quick = 100\n",
        "iterations_per_episode_quick = 1000\n",
        "\n",
        "# === ä¸­è¦æ¨¡å®Ÿé¨“ç”¨ï¼ˆç´„30åˆ†ï¼‰ ===\n",
        "n_episodes_mid = 1000\n",
        "iterations_per_episode_mid = 5000\n",
        "\n",
        "# === ãƒ•ãƒ«å®Ÿé¨“ç”¨ï¼ˆ8-12æ™‚é–“ï¼‰- è«–æ–‡ã®å®Œå…¨å†ç¾ ===\n",
        "n_episodes_full = 50000\n",
        "iterations_per_episode_full = 25000\n",
        "\n",
        "# å®Ÿè¡Œã™ã‚‹å®Ÿé¨“ã‚’é¸æŠï¼ˆä¸‹è¨˜ã®ã†ã¡1ã¤ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦ãã ã•ã„ï¼‰\n",
        "\n",
        "# 1. ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ\n",
        "print('ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿé¨“ã‚’é–‹å§‹...')\n",
        "agents, env, history = train_agents(\n",
        "    n_episodes=n_episodes_quick,\n",
        "    iterations_per_episode=iterations_per_episode_quick,\n",
        "    learning_rate=0.15,\n",
        "    discount_factor=0.95,\n",
        "    epsilon_decay_beta=4e-6,\n",
        "    memory_length=1,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 2. ä¸­è¦æ¨¡å®Ÿé¨“ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ï¼‰\n",
        "# print('ğŸš€ ä¸­è¦æ¨¡å®Ÿé¨“ã‚’é–‹å§‹...')\n",
        "# agents, env, history = train_agents(\n",
        "#     n_episodes=n_episodes_mid,\n",
        "#     iterations_per_episode=iterations_per_episode_mid,\n",
        "#     learning_rate=0.15,\n",
        "#     discount_factor=0.95,\n",
        "#     epsilon_decay_beta=4e-6,\n",
        "#     memory_length=1,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# 3. ãƒ•ãƒ«å®Ÿé¨“ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ï¼‰\n",
        "# print('ğŸš€ ãƒ•ãƒ«å®Ÿé¨“ï¼ˆè«–æ–‡ãƒ¬ãƒ™ãƒ«ï¼‰ã‚’é–‹å§‹...')\n",
        "# print('âš ï¸  äºˆæƒ³å®Ÿè¡Œæ™‚é–“: 8-12æ™‚é–“')\n",
        "# agents, env, history = train_agents(\n",
        "#     n_episodes=n_episodes_full,\n",
        "#     iterations_per_episode=iterations_per_episode_full,\n",
        "#     learning_rate=0.15,\n",
        "#     discount_factor=0.95,\n",
        "#     epsilon_decay_beta=4e-6,\n",
        "#     memory_length=1,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "print('\\nâœ… å­¦ç¿’å®Œäº†!')\n",
        "print(f'Final individual profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f}')\n",
        "print(f'Final joint profit: {history[\"training_summary\"][\"final_joint_profit\"]:.4f}')\n",
        "print(f'Nash ratio (individual): {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. å­¦ç¿’å±¥æ­´ã®å¯è¦–åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å­¦ç¿’çµæœã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# å€‹åˆ¥åˆ©ç›Šã®æ¨ç§»\n",
        "axes[0, 0].plot(history['episodes'], history['individual_profits'], 'b-', linewidth=2)\n",
        "axes[0, 0].axhline(y=nash_eq['individual_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
        "axes[0, 0].axhline(y=coop_eq['individual_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
        "axes[0, 0].set_title('Individual Profits', fontsize=14)\n",
        "axes[0, 0].set_xlabel('Episode')\n",
        "axes[0, 0].set_ylabel('Profit')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# åˆè¨ˆåˆ©ç›Šã®æ¨ç§»\n",
        "axes[0, 1].plot(history['episodes'], history['joint_profits'], 'b-', linewidth=2)\n",
        "axes[0, 1].axhline(y=nash_eq['joint_profit'], color='r', linestyle='--', label='Nash', linewidth=2)\n",
        "axes[0, 1].axhline(y=coop_eq['joint_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
        "axes[0, 1].set_title('Joint Profits', fontsize=14)\n",
        "axes[0, 1].set_xlabel('Episode')\n",
        "axes[0, 1].set_ylabel('Profit')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Epsilonæ¸›è¡°\n",
        "axes[1, 0].plot(history['episodes'], history['epsilon_values'], 'purple', linewidth=2)\n",
        "axes[1, 0].set_title('Epsilon Decay', fontsize=14)\n",
        "axes[1, 0].set_xlabel('Episode')\n",
        "axes[1, 0].set_ylabel('Epsilon')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Nashæ¯”\n",
        "nash_ratios = [p / nash_eq['individual_profit'] for p in history['individual_profits']]\n",
        "axes[1, 1].plot(history['episodes'], nash_ratios, 'orange', linewidth=2)\n",
        "axes[1, 1].axhline(y=1.0, color='r', linestyle='--', label='Nash', linewidth=2)\n",
        "axes[1, 1].axhline(y=coop_eq['individual_profit'] / nash_eq['individual_profit'], color='g', linestyle='--', label='Cooperative', linewidth=2)\n",
        "axes[1, 1].set_title('Individual Profit / Nash Profit', fontsize=14)\n",
        "axes[1, 1].set_xlabel('Episode')\n",
        "axes[1, 1].set_ylabel('Ratio')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# æœ€çµ‚çµæœã®è¡¨ç¤º\n",
        "print('ğŸ“ˆ æœ€çµ‚çµæœ:')\n",
        "print(f'Individual Profit: {history[\"training_summary\"][\"final_individual_profit\"]:.4f} (Nashæ¯”: {history[\"training_summary\"][\"nash_ratio_individual\"]:.3f})')\n",
        "print(f'Joint Profit: {history[\"training_summary\"][\"final_joint_profit\"]:.4f}')\n",
        "print(f'Final Epsilon: {history[\"training_summary\"][\"final_epsilon\"]:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ä¸¦åˆ—å®Ÿé¨“ã®å®Ÿè¡Œä¾‹\n",
        "\n",
        "ã‚ˆã‚Šå¤§è¦æ¨¡ãªå®Ÿé¨“ã‚’è¡Œã„ãŸã„å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === ä¸¦åˆ—å®Ÿé¨“ï¼ˆTable A.2ã®å®Œå…¨å†ç¾ï¼‰ ===\n",
        "# âš ï¸ é‡è¦: ãƒ•ãƒ«å®Ÿé¨“ã¯8-12æ™‚é–“ã‹ã‹ã‚Šã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦æ®µéšçš„ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# 1. ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆç´„10åˆ†ï¼‰- å‹•ä½œç¢ºèªç”¨\n",
        "print(\"ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆä¸¦åˆ—å®Ÿé¨“ã‚’é–‹å§‹...\")\n",
        "!python -m myproject.scripts.table_a2_parallel --episodes 1000 --n-seeds 2 --n-sessions 2 --max-workers 2\n",
        "\n",
        "# 2. ä¸­è¦æ¨¡å®Ÿé¨“ï¼ˆç´„60åˆ†ï¼‰- ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œ\n",
        "# print(\"ğŸš€ ä¸­è¦æ¨¡ä¸¦åˆ—å®Ÿé¨“ã‚’é–‹å§‹...\")\n",
        "# !python -m myproject.scripts.table_a2_parallel --episodes 5000 --n-seeds 5 --n-sessions 2 --max-workers 4\n",
        "\n",
        "# 3. ãƒ•ãƒ«å®Ÿé¨“ï¼ˆ8-12æ™‚é–“ï¼‰- è«–æ–‡ã®å®Œå…¨å†ç¾ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œï¼‰\n",
        "# print(\"ğŸš€ ãƒ•ãƒ«ä¸¦åˆ—å®Ÿé¨“ï¼ˆTable A.2å®Œå…¨å†ç¾ï¼‰ã‚’é–‹å§‹...\")\n",
        "# print(\"ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: 50,000ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ Ã— 10ã‚·ãƒ¼ãƒ‰\")\n",
        "# print(\"â° äºˆæƒ³å®Ÿè¡Œæ™‚é–“: 8-12æ™‚é–“\")\n",
        "# print()\n",
        "# !python -m myproject.scripts.table_a2_parallel --episodes 50000 --n-seeds 10 --n-sessions 4 --max-workers 4 --output-dir results\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "print(f\"\\nâ° å®Ÿè¡Œæ™‚é–“: {elapsed_time/60:.1f}åˆ†\")\n",
        "print(\"âœ… ä¸¦åˆ—å®Ÿé¨“å®Œäº†!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨åˆ†æ\n",
        "\n",
        "ä¸¦åˆ—å®Ÿé¨“ã‚’å®Ÿè¡Œã—ãŸå ´åˆã€çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã§ãã¾ã™ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª\n",
        "print(\"ğŸ“ å®Ÿé¨“çµæœãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
        "if os.path.exists('results'):\n",
        "    result_files = []\n",
        "    for file in os.listdir('results'):\n",
        "        if file.endswith('.json'):\n",
        "            print(f\"  ğŸ“Š {file}\")\n",
        "            result_files.append(file)\n",
        "        elif file.endswith('.csv'):\n",
        "            print(f\"  ğŸ“ˆ {file}\")\n",
        "    \n",
        "    # æœ€æ–°ã®çµæœã‚’åˆ†æ\n",
        "    if result_files:\n",
        "        latest_result = max(result_files, key=lambda f: os.path.getctime(f'results/{f}'))\n",
        "        print(f\"\\nğŸ” æœ€æ–°çµæœã®åˆ†æ: {latest_result}\")\n",
        "        \n",
        "        with open(f'results/{latest_result}', 'r') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º\n",
        "        if 'aggregated_stats' in data:\n",
        "            stats = data['aggregated_stats']\n",
        "            print(f\"å€‹åˆ¥åˆ©ç›Šå¹³å‡: {stats.get('individual_profit_mean', 'N/A'):.4f}\")\n",
        "            print(f\"å€‹åˆ¥åˆ©ç›Šæ¨™æº–åå·®: {stats.get('individual_profit_std', 'N/A'):.4f}\")\n",
        "            print(f\"åˆè¨ˆåˆ©ç›Šå¹³å‡: {stats.get('joint_profit_mean', 'N/A'):.4f}\")\n",
        "            print(f\"åˆè¨ˆåˆ©ç›Šæ¨™æº–åå·®: {stats.get('joint_profit_std', 'N/A'):.4f}\")\n",
        "        \n",
        "        # Table A.2å½¢å¼ã®çµæœè¡¨ç¤º\n",
        "        if 'sessions' in data:\n",
        "            sessions = data['sessions']\n",
        "            df = pd.DataFrame(sessions)\n",
        "            if not df.empty:\n",
        "                print(f\"\\nğŸ“Š Table A.2 ã‚¹ã‚¿ã‚¤ãƒ«ã®çµæœ:\")\n",
        "                print(f\"ã‚·ãƒ¼ãƒ‰æ•°: {len(df['seed'].unique())}\")\n",
        "                print(f\"ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {len(df)}\")\n",
        "                print(f\"å€‹åˆ¥åˆ©ç›Š: {df['final_individual_profit'].mean():.4f} Â± {df['final_individual_profit'].std():.4f}\")\n",
        "                print(f\"åˆè¨ˆåˆ©ç›Š: {df['final_joint_profit'].mean():.4f} Â± {df['final_joint_profit'].std():.4f}\")\n",
        "                print(f\"Nashæ¯” (å€‹åˆ¥): {df['nash_ratio_individual'].mean():.3f}\")\n",
        "        \n",
        "        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ\n",
        "        print(f\"\\nğŸ’¾ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "        files.download(f'results/{latest_result}')\n",
        "        \n",
        "else:\n",
        "    print(\"  âŒ çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšä¸¦åˆ—å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# å›³è¡¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª\n",
        "print(\"\\nğŸ–¼ï¸ å›³è¡¨ãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
        "if os.path.exists('figs'):\n",
        "    for file in os.listdir('figs'):\n",
        "        if file.endswith(('.png', '.pdf')):\n",
        "            print(f\"  ğŸ“ˆ {file}\")\n",
        "            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®å›³è¡¨ï¼‰\n",
        "            file_size = os.path.getsize(f'figs/{file}')\n",
        "            if file_size > 10000:  # 10KBä»¥ä¸Š\n",
        "                print(f\"    ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... ({file_size/1024:.1f}KB)\")\n",
        "                files.download(f'figs/{file}')\n",
        "else:\n",
        "    print(\"  âŒ å›³è¡¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
        "\n",
        "print(\"\\nâœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. ğŸ“‹ è«–æ–‡ãƒ¬ãƒ™ãƒ«å®Ÿé¨“ã®å®Ÿè¡Œæ‰‹é †\n",
        "\n",
        "**Calvano et al. (2020) Table A.2ã®å®Œå…¨å†ç¾**ã‚’è¡Œã†å ´åˆã®æ¨å¥¨æ‰‹é †ï¼š\n",
        "\n",
        "### ã‚¹ãƒ†ãƒƒãƒ—1: å‹•ä½œç¢ºèª\n",
        "- ã¾ãš**ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³4 & 6ï¼‰ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèª\n",
        "\n",
        "### ã‚¹ãƒ†ãƒƒãƒ—2: ä¸­è¦æ¨¡å®Ÿé¨“\n",
        "- **ä¸­è¦æ¨¡å®Ÿé¨“**ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³6ï¼‰ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œï¼ˆç´„60åˆ†ï¼‰\n",
        "- çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ç¢ºèª\n",
        "\n",
        "### ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ•ãƒ«å®Ÿé¨“\n",
        "- **ãƒ•ãƒ«å®Ÿé¨“**ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³6ï¼‰ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œ\n",
        "- âš ï¸ **8-12æ™‚é–“**ã‹ã‹ã‚‹ãŸã‚ã€æ™‚é–“ã«ä½™è£•ãŒã‚ã‚‹ã¨ãã«å®Ÿè¡Œ\n",
        "- å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š\n",
        "  - **50,000ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ Ã— 10ã‚·ãƒ¼ãƒ‰**\n",
        "  - **25,000 iterations per episode**\n",
        "  - **è«–æ–‡ã¨åŒä¸€ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**\n",
        "\n",
        "### æœŸå¾…ã•ã‚Œã‚‹çµæœï¼ˆè«–æ–‡Table A.2ï¼‰\n",
        "- **å€‹åˆ¥åˆ©ç›Š**: 0.18 Â± 0.03\n",
        "- **åˆè¨ˆåˆ©ç›Š**: 0.26 Â± 0.04  \n",
        "- **Nashæ¯”**: ç´„1.2-1.4 (å”èª¿çš„è¡Œå‹•ã®è¨¼æ‹ )\n",
        "\n",
        "### ğŸ’¡ ãƒ’ãƒ³ãƒˆ\n",
        "- Colab Pro/Pro+ã®ä½¿ç”¨ã‚’æ¨å¥¨ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆé˜²æ­¢ï¼‰\n",
        "- å®Ÿé¨“ä¸­ã¯ã‚¿ãƒ–ã‚’é–‰ã˜ãªã„ã§ãã ã•ã„\n",
        "- çµæœã¯è‡ªå‹•çš„ã«`results/`ã«ä¿å­˜ã•ã‚Œã¾ã™\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
>>>>>>> main
