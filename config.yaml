# Calvano et al. (2020) Q-learning Configuration
# 卒論向け再現実装用設定

# Environment Parameters (Demand Model)
environment:
  n_agents: 2
  demand_intercept: 0.0        # a_0 (outside option utility)
  demand_slope: 0.25           # μ (price sensitivity parameter)
  marginal_cost: 1.0           # c (marginal cost)
  product_quality: 2.0         # a_i (product quality, same for all)

# Price Grid Parameters
grid:
  size: 15                     # m = 15 price points
  extension: 0.1               # ξ = 0.1 (grid extension parameter)

# Q-learning Parameters
qlearning:
  learning_rate: 0.15          # α (Q-learning step size)
  discount_factor: 0.95        # γ (future reward discount)
  epsilon_initial: 1.0         # Initial exploration rate
  epsilon_decay_beta: 9.21e-5  # β calculated for ε(25000) ≈ 0.1
  memory_length: 1             # k = 1 (state memory periods)

# Training Parameters
training:
  n_episodes: 2000             # Maximum episodes
  iterations_per_episode: 25000 # Iterations within each episode

# Multi-seed Validation
validation:
  n_seeds: 5                   # Number of random seeds for statistical validation
  seeds: [42, 123, 456, 789, 999]

# Output Configuration
output:
  save_results: true
  results_dir: "results"
